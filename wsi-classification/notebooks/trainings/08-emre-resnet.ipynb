{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 608,
     "status": "ok",
     "timestamp": 1696597863950,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "qRtZIVIq3ijl",
    "outputId": "13ca0887-84ac-47ca-bda1-47539d491b8e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct  6 13:11:02 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    42W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = \"\\n\".join(gpu_info)\n",
    "if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU\")\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696597863950,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "3jvmaRGH3tex",
    "outputId": "17225ce9-c1ba-41ea-fc7b-3f259ed21de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 89.6 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print(\"Your runtime has {:.1f} gigabytes of available RAM\\n\".format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"Not using a high-RAM runtime\")\n",
    "else:\n",
    "    print(\"You are using a high-RAM runtime!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13050,
     "status": "ok",
     "timestamp": 1696597876998,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "a7IVwsR23tcY",
    "outputId": "84c66296-5cae-449a-f4d7-6abee1cdbdf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -qU\n",
    "!pip install -U tensorflow\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2411,
     "status": "ok",
     "timestamp": 1696597879404,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "Lyxfi0R63taW",
    "outputId": "d6a77129-4f05-47cf-a236-807b23c56858"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount the Google Drive to access the files\n",
    "drive.mount(\"/content/gdrive/\")\n",
    "work_directory = \"/content/gdrive/MyDrive/wsi_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3735,
     "status": "ok",
     "timestamp": 1696597883136,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "kTE-GHq03tXu",
    "outputId": "3fff9da0-9563-4b33-b687-850c63d48e91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Add the path to your project root directory\n",
    "if work_directory not in sys.path:\n",
    "    sys.path.append(work_directory)\n",
    "\n",
    "# my utility functions\n",
    "from utils.general import create_directory\n",
    "from utils.dataloader import select_case_data\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "import wandb\n",
    "\n",
    "# load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(work_directory, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696597883136,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "01W6Ar7q3tVc",
    "outputId": "00196224-2325-444c-c738-b021c01b85d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: /content/gdrive/MyDrive/wsi_code/runs/40k/resnet\n"
     ]
    }
   ],
   "source": [
    "# Define data directories\n",
    "DATASETS_PATH = os.path.join(work_directory, \"datasets\")\n",
    "PROCESSED_PATH = os.path.join(DATASETS_PATH, \"processed\")\n",
    "hdf5_file = os.path.join(PROCESSED_PATH, \"patchs_384_40k.hdf5\")\n",
    "run_dir = os.path.join(work_directory, \"runs\", \"40k\")\n",
    "\n",
    "# Create directories with datetime\n",
    "model_dir = os.path.join(run_dir, \"resnet\")\n",
    "\n",
    "# Create the directories\n",
    "create_directory(model_dir)\n",
    "\n",
    "# Get the current datetime\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "log_path = os.path.join(model_dir, f\"{current_datetime}.log\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    filename=log_path,  # Specify the file name and path\n",
    "    filemode=\"w\",  # 'w' for write mode, use 'a' to append to an existing file\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 281172,
     "status": "ok",
     "timestamp": 1696598165056,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "CDXhFkJepSkW"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "logger.info(\"Loading and preprocessing data...\")\n",
    "validation_images, validation_labels, train_images, train_labels = select_case_data(\n",
    "    hdf5_file, selected_cases=[4]\n",
    ")\n",
    "\n",
    "# Define a normalization layer\n",
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = np.unique(train_labels).shape[\n",
    "    0\n",
    "]  # Replace with the actual number of classes\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "validation_labels = tf.keras.utils.to_categorical(validation_labels, num_classes)\n",
    "\n",
    "\n",
    "def preprocess_data(images, labels):\n",
    "    images = normalization_layer(images)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def create_and_preprocess_dataset(\n",
    "    images, labels, batch_size, augment=False, shuffle_buffer_size=1000\n",
    "):\n",
    "    # Create a dataset from the input images and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "    # Shuffle the dataset for randomness\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if augment:\n",
    "        # Apply data augmentation within the dataset pipeline\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_up_down(x), y))\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta=0.05), y)\n",
    "        )\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_contrast(x, lower=0.9, upper=1.1), y)\n",
    "        )\n",
    "\n",
    "    # Normalize the images\n",
    "    dataset = dataset.map(preprocess_data)\n",
    "\n",
    "    # Batch the dataset\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Prefetch for efficient loading during training\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Create TensorFlow datasets and apply normalization\n",
    "logger.info(\"Creating datasets and applying normalization...\")\n",
    "\n",
    "batch_size = 16  # You can adjust this based on your available memory\n",
    "num_parallel_calls = tf.data.AUTOTUNE\n",
    "\n",
    "normalized_validation_ds = create_and_preprocess_dataset(\n",
    "    validation_images, validation_labels, batch_size=batch_size\n",
    ")\n",
    "normalized_train_ds = create_and_preprocess_dataset(\n",
    "    train_images, train_labels, augment=False, batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Delete unused variables to free up memory\n",
    "del validation_images, validation_labels, train_images, train_labels\n",
    "\n",
    "logger.info(\"Data loading and preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 2537,
     "status": "ok",
     "timestamp": 1696598167590,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "thxBWBvl392L"
   },
   "outputs": [],
   "source": [
    "resnet = tf.keras.applications.ResNet50V2(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    classifier_activation=\"softmax\",\n",
    "    input_shape=(384, 384, 3),\n",
    ")\n",
    "\n",
    "resnet.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(resnet.output)\n",
    "# x = Dropout(0.5)(x)\n",
    "# x = Dropout(0.5)(resnet.output)\n",
    "# x = Conv2D(filters=256, kernel_size=(1,1))(resnet.output)\n",
    "# x = Flatten()(resnet.output)\n",
    "# x = Dense(4096, activation=\"relu\")(x)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(resnet.inputs, outputs, name=\"ResNet50V2\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1696598167590,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "hH5Gtu0bn7Vu"
   },
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define ReduceLROnPlateau callback\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor=\"loss\", factor=0.5, patience=2, min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=model_dir,\n",
    "    histogram_freq=1,  # Enable histogram computation\n",
    "    write_graph=True,  # Write model graph to file\n",
    "    write_images=True,  # Write model weights to file\n",
    "    update_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 8260,
     "status": "ok",
     "timestamp": 1696598175845,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "UkAbjtVzn7Vv",
    "outputId": "12e21c0f-7fd6-4095-d12b-cb96d6389be1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maemreusta\u001b[0m (\u001b[33mhacettepe-cerrahpasa-sts\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20231006_131612-z4hjc2og</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/z4hjc2og' target=\"_blank\">logical-firefly-34</a></strong> to <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/z4hjc2og' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/z4hjc2og</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "else:\n",
    "    print(\"WANDB_API_KEY not found in the .env file.\")\n",
    "\n",
    "# Before wandb.init, call wandb.tensorboard.patch\n",
    "wandb.tensorboard.patch(\n",
    "    root_logdir=model_dir\n",
    ")  # Replace model_dir with your log directory\n",
    "wandb.init(\n",
    "    project=\"wsi-classification-40k\",\n",
    "    sync_tensorboard=True,\n",
    "    entity=\"hacettepe-cerrahpasa-sts\",\n",
    "    notes=\"resnet_cross_4_final\",\n",
    "    tags=[\"resnet\", \"50v2\", \"cross_4\", \"final\"],\n",
    ")\n",
    "# Initialize wandb callback\n",
    "wandb_callback = wandb.keras.WandbCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3279987,
     "status": "ok",
     "timestamp": 1696601455829,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "iPGfhfsV5HlE",
    "outputId": "b4183f16-0a67-4149-f5c0-aeac1c4e706b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0869 - categorical_accuracy: 0.9778 - precision: 0.9786 - recall: 0.9771"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 112s 51ms/step - loss: 0.0869 - categorical_accuracy: 0.9778 - precision: 0.9787 - recall: 0.9772 - val_loss: 7.9206 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1043 - categorical_accuracy: 0.9796 - precision: 0.9802 - recall: 0.9791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.1043 - categorical_accuracy: 0.9796 - precision: 0.9802 - recall: 0.9791 - val_loss: 6.0680 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0586 - categorical_accuracy: 0.9846 - precision: 0.9852 - recall: 0.9842"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.0586 - categorical_accuracy: 0.9847 - precision: 0.9852 - recall: 0.9842 - val_loss: 5.7416 - val_categorical_accuracy: 0.2501 - val_precision: 0.2501 - val_recall: 0.2501 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0424 - categorical_accuracy: 0.9882 - precision: 0.9886 - recall: 0.9879"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 103s 51ms/step - loss: 0.0423 - categorical_accuracy: 0.9882 - precision: 0.9886 - recall: 0.9879 - val_loss: 5.6218 - val_categorical_accuracy: 0.2506 - val_precision: 0.2507 - val_recall: 0.2506 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 84s 42ms/step - loss: 0.0351 - categorical_accuracy: 0.9892 - precision: 0.9896 - recall: 0.9888 - val_loss: 5.7050 - val_categorical_accuracy: 0.2508 - val_precision: 0.2509 - val_recall: 0.2506 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "2000/2000 [==============================] - 85s 42ms/step - loss: 0.0306 - categorical_accuracy: 0.9915 - precision: 0.9919 - recall: 0.9912 - val_loss: 5.8653 - val_categorical_accuracy: 0.2512 - val_precision: 0.2513 - val_recall: 0.2510 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0257 - categorical_accuracy: 0.9923 - precision: 0.9926 - recall: 0.9919 - val_loss: 6.0505 - val_categorical_accuracy: 0.2516 - val_precision: 0.2517 - val_recall: 0.2512 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - 85s 42ms/step - loss: 0.0250 - categorical_accuracy: 0.9932 - precision: 0.9934 - recall: 0.9930 - val_loss: 5.8997 - val_categorical_accuracy: 0.2537 - val_precision: 0.2539 - val_recall: 0.2530 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0207 - categorical_accuracy: 0.9938 - precision: 0.9942 - recall: 0.9936 - val_loss: 6.0255 - val_categorical_accuracy: 0.2537 - val_precision: 0.2538 - val_recall: 0.2533 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 85s 42ms/step - loss: 0.0206 - categorical_accuracy: 0.9942 - precision: 0.9945 - recall: 0.9939 - val_loss: 6.2036 - val_categorical_accuracy: 0.2542 - val_precision: 0.2542 - val_recall: 0.2536 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0184 - categorical_accuracy: 0.9948 - precision: 0.9950 - recall: 0.9945 - val_loss: 5.9500 - val_categorical_accuracy: 0.2556 - val_precision: 0.2561 - val_recall: 0.2553 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 85s 42ms/step - loss: 0.0169 - categorical_accuracy: 0.9951 - precision: 0.9953 - recall: 0.9949 - val_loss: 5.8223 - val_categorical_accuracy: 0.2582 - val_precision: 0.2577 - val_recall: 0.2566 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0173 - categorical_accuracy: 0.9952 - precision: 0.9956 - recall: 0.9949 - val_loss: 6.1361 - val_categorical_accuracy: 0.2585 - val_precision: 0.2579 - val_recall: 0.2570 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0146 - categorical_accuracy: 0.9959 - precision: 0.9962 - recall: 0.9957 - val_loss: 6.2463 - val_categorical_accuracy: 0.2595 - val_precision: 0.2592 - val_recall: 0.2584 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0138 - categorical_accuracy: 0.9965 - precision: 0.9967 - recall: 0.9964 - val_loss: 6.3170 - val_categorical_accuracy: 0.2626 - val_precision: 0.2627 - val_recall: 0.2619 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 85s 42ms/step - loss: 0.0133 - categorical_accuracy: 0.9958 - precision: 0.9960 - recall: 0.9958 - val_loss: 6.0621 - val_categorical_accuracy: 0.2637 - val_precision: 0.2642 - val_recall: 0.2631 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 86s 43ms/step - loss: 0.0127 - categorical_accuracy: 0.9969 - precision: 0.9971 - recall: 0.9967 - val_loss: 6.3669 - val_categorical_accuracy: 0.2611 - val_precision: 0.2616 - val_recall: 0.2606 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0130 - categorical_accuracy: 0.9967 - precision: 0.9968 - recall: 0.9966 - val_loss: 6.2002 - val_categorical_accuracy: 0.2644 - val_precision: 0.2645 - val_recall: 0.2630 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0111 - categorical_accuracy: 0.9970 - precision: 0.9972 - recall: 0.9969 - val_loss: 6.2238 - val_categorical_accuracy: 0.2674 - val_precision: 0.2674 - val_recall: 0.2661 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0122 - categorical_accuracy: 0.9970 - precision: 0.9972 - recall: 0.9969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.0122 - categorical_accuracy: 0.9970 - precision: 0.9972 - recall: 0.9969 - val_loss: 5.5194 - val_categorical_accuracy: 0.2758 - val_precision: 0.2754 - val_recall: 0.2736 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 85s 42ms/step - loss: 0.0104 - categorical_accuracy: 0.9973 - precision: 0.9974 - recall: 0.9972 - val_loss: 6.0259 - val_categorical_accuracy: 0.2724 - val_precision: 0.2733 - val_recall: 0.2719 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 86s 43ms/step - loss: 0.0096 - categorical_accuracy: 0.9975 - precision: 0.9975 - recall: 0.9972 - val_loss: 6.0769 - val_categorical_accuracy: 0.2722 - val_precision: 0.2721 - val_recall: 0.2710 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 86s 43ms/step - loss: 0.0085 - categorical_accuracy: 0.9977 - precision: 0.9978 - recall: 0.9976 - val_loss: 6.2655 - val_categorical_accuracy: 0.2744 - val_precision: 0.2742 - val_recall: 0.2727 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0095 - categorical_accuracy: 0.9973 - precision: 0.9975 - recall: 0.9973 - val_loss: 5.8227 - val_categorical_accuracy: 0.2805 - val_precision: 0.2804 - val_recall: 0.2785 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0084 - categorical_accuracy: 0.9978 - precision: 0.9980 - recall: 0.9978 - val_loss: 6.0734 - val_categorical_accuracy: 0.2751 - val_precision: 0.2755 - val_recall: 0.2743 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 85s 42ms/step - loss: 0.0090 - categorical_accuracy: 0.9976 - precision: 0.9977 - recall: 0.9976 - val_loss: 6.1198 - val_categorical_accuracy: 0.2786 - val_precision: 0.2790 - val_recall: 0.2771 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0085 - categorical_accuracy: 0.9979 - precision: 0.9980 - recall: 0.9978 - val_loss: 6.1096 - val_categorical_accuracy: 0.2816 - val_precision: 0.2822 - val_recall: 0.2806 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0113 - categorical_accuracy: 0.9972 - precision: 0.9974 - recall: 0.9971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.0113 - categorical_accuracy: 0.9972 - precision: 0.9974 - recall: 0.9971 - val_loss: 5.0825 - val_categorical_accuracy: 0.2961 - val_precision: 0.2978 - val_recall: 0.2941 - lr: 2.5000e-05\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 85s 43ms/step - loss: 0.0095 - categorical_accuracy: 0.9978 - precision: 0.9980 - recall: 0.9976 - val_loss: 5.3127 - val_categorical_accuracy: 0.2907 - val_precision: 0.2910 - val_recall: 0.2881 - lr: 2.5000e-05\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.0158 - categorical_accuracy: 0.9954 - precision: 0.9958 - recall: 0.9949"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 105s 53ms/step - loss: 0.0158 - categorical_accuracy: 0.9954 - precision: 0.9958 - recall: 0.9949 - val_loss: 4.2017 - val_categorical_accuracy: 0.3250 - val_precision: 0.3260 - val_recall: 0.3203 - lr: 1.2500e-05\n",
      "Epoch 31/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0164 - categorical_accuracy: 0.9954 - precision: 0.9959 - recall: 0.9952"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 103s 51ms/step - loss: 0.0164 - categorical_accuracy: 0.9954 - precision: 0.9959 - recall: 0.9952 - val_loss: 4.0505 - val_categorical_accuracy: 0.3305 - val_precision: 0.3326 - val_recall: 0.3260 - lr: 1.2500e-05\n",
      "Epoch 32/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0344 - categorical_accuracy: 0.9887 - precision: 0.9898 - recall: 0.9876"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.0344 - categorical_accuracy: 0.9887 - precision: 0.9898 - recall: 0.9876 - val_loss: 3.1712 - val_categorical_accuracy: 0.3865 - val_precision: 0.3905 - val_recall: 0.3767 - lr: 6.2500e-06\n",
      "Epoch 33/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0374 - categorical_accuracy: 0.9880 - precision: 0.9890 - recall: 0.9870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.0373 - categorical_accuracy: 0.9880 - precision: 0.9890 - recall: 0.9870 - val_loss: 3.0267 - val_categorical_accuracy: 0.3971 - val_precision: 0.4015 - val_recall: 0.3873 - lr: 6.2500e-06\n",
      "Epoch 34/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0843 - categorical_accuracy: 0.9700 - precision: 0.9722 - recall: 0.9670"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.0843 - categorical_accuracy: 0.9701 - precision: 0.9723 - recall: 0.9670 - val_loss: 2.2857 - val_categorical_accuracy: 0.4690 - val_precision: 0.4773 - val_recall: 0.4520 - lr: 3.1250e-06\n",
      "Epoch 35/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0876 - categorical_accuracy: 0.9694 - precision: 0.9718 - recall: 0.9666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_131612-z4hjc2og/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 104s 52ms/step - loss: 0.0875 - categorical_accuracy: 0.9694 - precision: 0.9718 - recall: 0.9667 - val_loss: 2.2105 - val_categorical_accuracy: 0.4761 - val_precision: 0.4846 - val_recall: 0.4577 - lr: 3.1250e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data=normalized_validation_ds,\n",
    "    epochs=100,\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        wandb_callback,\n",
    "        early_stopping,\n",
    "        reduce_lr_on_plateau,\n",
    "        tensorboard_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 45296,
     "status": "ok",
     "timestamp": 1696601501107,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "2BvLrKLQ-Yak",
    "outputId": "530ff3e1-7703-4c63-9f3a-2c8e5b761ff0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td></td></tr><tr><td>epoch</td><td></td></tr><tr><td>global_step</td><td></td></tr><tr><td>loss</td><td></td></tr><tr><td>precision</td><td></td></tr><tr><td>recall</td><td></td></tr><tr><td>train/epoch_categorical_accuracy</td><td></td></tr><tr><td>train/epoch_loss</td><td></td></tr><tr><td>train/epoch_lr</td><td></td></tr><tr><td>train/epoch_precision</td><td></td></tr><tr><td>train/epoch_recall</td><td></td></tr><tr><td>train/global_step</td><td></td></tr><tr><td>val_categorical_accuracy</td><td></td></tr><tr><td>val_loss</td><td></td></tr><tr><td>val_precision</td><td></td></tr><tr><td>val_recall</td><td></td></tr><tr><td>validation/epoch_categorical_accuracy</td><td></td></tr><tr><td>validation/epoch_loss</td><td></td></tr><tr><td>validation/epoch_precision</td><td></td></tr><tr><td>validation/epoch_recall</td><td></td></tr><tr><td>validation/evaluation_categorical_accuracy_vs_iterations</td><td></td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td></td></tr><tr><td>validation/evaluation_precision_vs_iterations</td><td></td></tr><tr><td>validation/evaluation_recall_vs_iterations</td><td></td></tr><tr><td>validation/global_step</td><td></td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>34</td></tr><tr><td>best_val_loss</td><td>2.2105</td></tr><tr><td>categorical_accuracy</td><td>0.96938</td></tr><tr><td>epoch</td><td>34</td></tr><tr><td>global_step</td><td>70000</td></tr><tr><td>loss</td><td>0.08755</td></tr><tr><td>precision</td><td>0.97182</td></tr><tr><td>recall</td><td>0.96666</td></tr><tr><td>train/epoch_categorical_accuracy</td><td>0.96938</td></tr><tr><td>train/epoch_loss</td><td>0.08755</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/epoch_precision</td><td>0.97182</td></tr><tr><td>train/epoch_recall</td><td>0.96666</td></tr><tr><td>train/global_step</td><td>34</td></tr><tr><td>val_categorical_accuracy</td><td>0.47613</td></tr><tr><td>val_loss</td><td>2.2105</td></tr><tr><td>val_precision</td><td>0.48465</td></tr><tr><td>val_recall</td><td>0.45775</td></tr><tr><td>validation/epoch_categorical_accuracy</td><td>0.47613</td></tr><tr><td>validation/epoch_loss</td><td>2.2105</td></tr><tr><td>validation/epoch_precision</td><td>0.48465</td></tr><tr><td>validation/epoch_recall</td><td>0.45775</td></tr><tr><td>validation/evaluation_categorical_accuracy_vs_iterations</td><td>0.47613</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>2.2105</td></tr><tr><td>validation/evaluation_precision_vs_iterations</td><td>0.48465</td></tr><tr><td>validation/evaluation_recall_vs_iterations</td><td>0.45775</td></tr><tr><td>validation/global_step</td><td>34</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">logical-firefly-34</strong> at: <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/z4hjc2og' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/z4hjc2og</a><br/>Synced 5 W&B file(s), 8996 media file(s), 60 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231006_131612-z4hjc2og/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1696601501107,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "3tLMjayp5LZk"
   },
   "outputs": [],
   "source": [
    "# runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}