{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 767,
     "status": "ok",
     "timestamp": 1696613997970,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "JR_e5BxWpv4e",
    "outputId": "06ad49d3-27f0-4aa8-8008-36285445c6d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct  6 17:39:56 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   41C    P0    48W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = \"\\n\".join(gpu_info)\n",
    "if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU\")\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696613997971,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "oZLZ9wC4pxTL",
    "outputId": "5ea4cca7-5a28-4564-8daa-3f72c87c02d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 89.6 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print(\"Your runtime has {:.1f} gigabytes of available RAM\\n\".format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"Not using a high-RAM runtime\")\n",
    "else:\n",
    "    print(\"You are using a high-RAM runtime!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12598,
     "status": "ok",
     "timestamp": 1696614010563,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "4h_4sqL6Eyz9",
    "outputId": "d6a15dc0-0246-43c6-c00f-e700081a528b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -qU\n",
    "!pip install -U tensorflow\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2275,
     "status": "ok",
     "timestamp": 1696614012834,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "x3VlRCDrF7sm",
    "outputId": "26ad2cca-cc5a-43f3-94d1-4ac599aff057"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount the Google Drive to access the files\n",
    "drive.mount(\"/content/gdrive/\")\n",
    "work_directory = \"/content/gdrive/MyDrive/wsi_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3245,
     "status": "ok",
     "timestamp": 1696614016077,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "kytvHMqiF8xd",
    "outputId": "10a5f4b7-cd77-40af-f737-1a4ed5cf2c38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Add the path to your project root directory\n",
    "if work_directory not in sys.path:\n",
    "    sys.path.append(work_directory)\n",
    "\n",
    "# my utility functions\n",
    "from utils.general import create_directory\n",
    "from utils.dataloader import select_case_data\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "import wandb\n",
    "\n",
    "# load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(work_directory, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1696614016077,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "K_n1niE7F-c_",
    "outputId": "1f9e96e4-4b7b-4260-b76d-7dd2709da3ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: /content/gdrive/MyDrive/wsi_code/runs/40k/efficientnetb0\n"
     ]
    }
   ],
   "source": [
    "# Define data directories\n",
    "DATASETS_PATH = os.path.join(work_directory, \"datasets\")\n",
    "PROCESSED_PATH = os.path.join(DATASETS_PATH, \"processed\")\n",
    "hdf5_file = os.path.join(PROCESSED_PATH, \"patchs_384_40k.hdf5\")\n",
    "run_dir = os.path.join(work_directory, \"runs\", \"40k\")\n",
    "\n",
    "# Create directories with datetime\n",
    "model_dir = os.path.join(run_dir, \"efficientnetb0\")\n",
    "\n",
    "# Create the directories\n",
    "create_directory(model_dir)\n",
    "\n",
    "# Get the current datetime\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "log_path = os.path.join(model_dir, f\"{current_datetime}.log\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    filename=log_path,  # Specify the file name and path\n",
    "    filemode=\"w\",  # 'w' for write mode, use 'a' to append to an existing file\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 279212,
     "status": "ok",
     "timestamp": 1696614296075,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "KFWTSg0sGCx5"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "logger.info(\"Loading and preprocessing data...\")\n",
    "validation_images, validation_labels, train_images, train_labels = select_case_data(\n",
    "    hdf5_file, selected_cases=[4]\n",
    ")\n",
    "\n",
    "# Define a normalization layer\n",
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = np.unique(train_labels).shape[\n",
    "    0\n",
    "]  # Replace with the actual number of classes\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "validation_labels = tf.keras.utils.to_categorical(validation_labels, num_classes)\n",
    "\n",
    "\n",
    "def preprocess_data(images, labels):\n",
    "    images = normalization_layer(images)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def create_and_preprocess_dataset(\n",
    "    images, labels, batch_size, augment=False, shuffle_buffer_size=1000\n",
    "):\n",
    "    # Create a dataset from the input images and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "    # Shuffle the dataset for randomness\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if augment:\n",
    "        # Apply data augmentation within the dataset pipeline\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_up_down(x), y))\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta=0.05), y)\n",
    "        )\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_contrast(x, lower=0.9, upper=1.1), y)\n",
    "        )\n",
    "\n",
    "    # Normalize the images\n",
    "    dataset = dataset.map(preprocess_data)\n",
    "\n",
    "    # Batch the dataset\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Prefetch for efficient loading during training\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Create TensorFlow datasets and apply normalization\n",
    "logger.info(\"Creating datasets and applying normalization...\")\n",
    "\n",
    "batch_size = 16  # You can adjust this based on your available memory\n",
    "num_parallel_calls = tf.data.AUTOTUNE\n",
    "\n",
    "normalized_validation_ds = create_and_preprocess_dataset(\n",
    "    validation_images, validation_labels, batch_size=batch_size\n",
    ")\n",
    "normalized_train_ds = create_and_preprocess_dataset(\n",
    "    train_images, train_labels, augment=False, batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Delete unused variables to free up memory\n",
    "del validation_images, validation_labels, train_images, train_labels\n",
    "\n",
    "logger.info(\"Data loading and preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 4593,
     "status": "ok",
     "timestamp": 1696614300649,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "Ar9wW1yrGEPC"
   },
   "outputs": [],
   "source": [
    "efficientnet = tf.keras.applications.EfficientNetV2S(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    classifier_activation=\"softmax\",\n",
    "    input_shape=(384, 384, 3),\n",
    ")\n",
    "\n",
    "efficientnet.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(efficientnet.output)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(efficientnet.inputs, outputs, name=\"EfficientNetV2S\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1696614300649,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "cGJC-kqQGFW-"
   },
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define ReduceLROnPlateau callback\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor=\"loss\", factor=0.5, patience=2, min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=model_dir,\n",
    "    histogram_freq=1,  # Enable histogram computation\n",
    "    write_graph=True,  # Write model graph to file\n",
    "    write_images=True,  # Write model weights to file\n",
    "    update_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 7425,
     "status": "ok",
     "timestamp": 1696614308069,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "Z89zUHjsGNL8",
    "outputId": "f2832673-edb0-4e95-e5c7-71662fff89b2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maemreusta\u001b[0m (\u001b[33mhacettepe-cerrahpasa-sts\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20231006_174505-n2wa4hje</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/n2wa4hje' target=\"_blank\">misunderstood-butterfly-44</a></strong> to <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/n2wa4hje' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/n2wa4hje</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "else:\n",
    "    print(\"WANDB_API_KEY not found in the .env file.\")\n",
    "\n",
    "# Before wandb.init, call wandb.tensorboard.patch\n",
    "wandb.tensorboard.patch(\n",
    "    root_logdir=model_dir\n",
    ")  # Replace model_dir with your log directory\n",
    "wandb.init(\n",
    "    project=\"wsi-classification-40k\",\n",
    "    sync_tensorboard=True,\n",
    "    entity=\"hacettepe-cerrahpasa-sts\",\n",
    "    notes=\"efficientnet_cross_4_final\",\n",
    "    tags=[\"efficientnet\", \"v2S\", \"cross_4\", \"final\"],\n",
    ")\n",
    "# Initialize wandb callback\n",
    "wandb_callback = wandb.keras.WandbCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2003809,
     "status": "ok",
     "timestamp": 1696616311873,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "f_2cLxrVGW-m",
    "outputId": "961d2789-0958-45a8-8ec6-720a269f609f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "   5/2000 [..............................] - ETA: 1:35 - loss: 1.1610 - categorical_accuracy: 0.9375 - precision: 0.0000e+00 - recall: 0.0000e+00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0438s vs `on_train_batch_end` time: 0.0898s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.2229 - categorical_accuracy: 0.9334 - precision: 0.9356 - recall: 0.9228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 203s 92ms/step - loss: 0.2227 - categorical_accuracy: 0.9335 - precision: 0.9356 - recall: 0.9229 - val_loss: 6.7976 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.2679 - categorical_accuracy: 0.9270 - precision: 0.9294 - recall: 0.9235"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:11.496002, resuming normal operation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 192s 96ms/step - loss: 0.2678 - categorical_accuracy: 0.9270 - precision: 0.9294 - recall: 0.9235 - val_loss: 5.7866 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.2483 - categorical_accuracy: 0.9304 - precision: 0.9334 - recall: 0.9271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 189s 95ms/step - loss: 0.2481 - categorical_accuracy: 0.9304 - precision: 0.9335 - recall: 0.9272 - val_loss: 5.7763 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.3404 - categorical_accuracy: 0.9113 - precision: 0.9156 - recall: 0.9055"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 190s 95ms/step - loss: 0.3403 - categorical_accuracy: 0.9113 - precision: 0.9156 - recall: 0.9056 - val_loss: 4.5791 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 2.5000e-05\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 129s 65ms/step - loss: 0.2986 - categorical_accuracy: 0.9162 - precision: 0.9205 - recall: 0.9112 - val_loss: 4.5799 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 2.5000e-05\n",
      "Epoch 6/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.4458 - categorical_accuracy: 0.8711 - precision: 0.8805 - recall: 0.8576"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 192s 96ms/step - loss: 0.4456 - categorical_accuracy: 0.8712 - precision: 0.8806 - recall: 0.8577 - val_loss: 3.5694 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 1.2500e-05\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 130s 65ms/step - loss: 0.4132 - categorical_accuracy: 0.8762 - precision: 0.8874 - recall: 0.8615 - val_loss: 3.7219 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 1.2500e-05\n",
      "Epoch 8/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6921 - categorical_accuracy: 0.7731 - precision: 0.7967 - recall: 0.7320"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 193s 97ms/step - loss: 0.6921 - categorical_accuracy: 0.7731 - precision: 0.7967 - recall: 0.7320 - val_loss: 2.7231 - val_categorical_accuracy: 0.2499 - val_precision: 0.2500 - val_recall: 0.2498 - lr: 6.2500e-06\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 0.6528 - categorical_accuracy: 0.7807 - precision: 0.8104 - recall: 0.7295"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 192s 96ms/step - loss: 0.6528 - categorical_accuracy: 0.7807 - precision: 0.8104 - recall: 0.7295 - val_loss: 2.7090 - val_categorical_accuracy: 0.2499 - val_precision: 0.2500 - val_recall: 0.2498 - lr: 6.2500e-06\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - ETA: 0s - loss: 1.0372 - categorical_accuracy: 0.5933 - precision: 0.6542 - recall: 0.4531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 192s 96ms/step - loss: 1.0372 - categorical_accuracy: 0.5933 - precision: 0.6542 - recall: 0.4531 - val_loss: 1.8623 - val_categorical_accuracy: 0.2529 - val_precision: 0.2623 - val_recall: 0.2499 - lr: 3.1250e-06\n",
      "Epoch 11/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.9587 - categorical_accuracy: 0.6245 - precision: 0.7167 - recall: 0.4699"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_174505-n2wa4hje/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 193s 97ms/step - loss: 0.9584 - categorical_accuracy: 0.6247 - precision: 0.7169 - recall: 0.4701 - val_loss: 1.8598 - val_categorical_accuracy: 0.2530 - val_precision: 0.2629 - val_recall: 0.2499 - lr: 3.1250e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data=normalized_validation_ds,\n",
    "    epochs=100,\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        wandb_callback,\n",
    "        early_stopping,\n",
    "        reduce_lr_on_plateau,\n",
    "        tensorboard_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 69788,
     "status": "ok",
     "timestamp": 1696616381627,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "ivFRgohDIxDv",
    "outputId": "da625746-8c14-4cc7-d5fc-868d59c94ba4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>█████▇▇▅▅▁▂</td></tr><tr><td>epoch</td><td>▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>global_step</td><td>▁▂▂▂▃▃▄▄▄▄▅▅▅▅▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>▁▁▁▂▂▃▃▅▅█▇</td></tr><tr><td>precision</td><td>█████▇▇▅▅▁▃</td></tr><tr><td>recall</td><td>█████▇▇▅▅▁▁</td></tr><tr><td>train/epoch_categorical_accuracy</td><td>█████▇▇▅▅▁▂</td></tr><tr><td>train/epoch_loss</td><td>▁▁▁▂▂▃▃▅▅█▇</td></tr><tr><td>train/epoch_lr</td><td>███▄▄▂▂▁▁▁▁</td></tr><tr><td>train/epoch_precision</td><td>█████▇▇▅▅▁▃</td></tr><tr><td>train/epoch_recall</td><td>█████▇▇▅▅▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▂▂▃▄▅▅▆▇▇█</td></tr><tr><td>val_categorical_accuracy</td><td>▁▁▁▁▁▁▁▁▁██</td></tr><tr><td>val_loss</td><td>█▇▇▅▅▃▄▂▂▁▁</td></tr><tr><td>val_precision</td><td>▁▁▁▁▁▁▁▁▁██</td></tr><tr><td>val_recall</td><td>███████▁▁▄▄</td></tr><tr><td>validation/epoch_categorical_accuracy</td><td>▁▁▁▁▁▁▁▁▁██</td></tr><tr><td>validation/epoch_loss</td><td>█▇▇▅▅▃▄▂▂▁▁</td></tr><tr><td>validation/epoch_precision</td><td>▁▁▁▁▁▁▁▁▁██</td></tr><tr><td>validation/epoch_recall</td><td>███████▁▁▄▄</td></tr><tr><td>validation/evaluation_categorical_accuracy_vs_iterations</td><td>▁▁▁▁▁▁▁▁▁██</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▇▇▅▅▃▄▂▂▁▁</td></tr><tr><td>validation/evaluation_precision_vs_iterations</td><td>▁▁▁▁▁▁▁▁▁██</td></tr><tr><td>validation/evaluation_recall_vs_iterations</td><td>███████▁▁▄▄</td></tr><tr><td>validation/global_step</td><td>▁▁▁▄▁▄▁▅▁▅▁▆▁▇▁▇▁█▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>1.85978</td></tr><tr><td>categorical_accuracy</td><td>0.62469</td></tr><tr><td>epoch</td><td>10</td></tr><tr><td>global_step</td><td>22000</td></tr><tr><td>loss</td><td>0.95838</td></tr><tr><td>precision</td><td>0.71688</td></tr><tr><td>recall</td><td>0.47009</td></tr><tr><td>train/epoch_categorical_accuracy</td><td>0.62469</td></tr><tr><td>train/epoch_loss</td><td>0.95838</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/epoch_precision</td><td>0.71688</td></tr><tr><td>train/epoch_recall</td><td>0.47009</td></tr><tr><td>train/global_step</td><td>10</td></tr><tr><td>val_categorical_accuracy</td><td>0.253</td></tr><tr><td>val_loss</td><td>1.85978</td></tr><tr><td>val_precision</td><td>0.26289</td></tr><tr><td>val_recall</td><td>0.24987</td></tr><tr><td>validation/epoch_categorical_accuracy</td><td>0.253</td></tr><tr><td>validation/epoch_loss</td><td>1.85978</td></tr><tr><td>validation/epoch_precision</td><td>0.26289</td></tr><tr><td>validation/epoch_recall</td><td>0.24987</td></tr><tr><td>validation/evaluation_categorical_accuracy_vs_iterations</td><td>0.253</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>1.85978</td></tr><tr><td>validation/evaluation_precision_vs_iterations</td><td>0.26289</td></tr><tr><td>validation/evaluation_recall_vs_iterations</td><td>0.24987</td></tr><tr><td>validation/global_step</td><td>10</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misunderstood-butterfly-44</strong> at: <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/n2wa4hje' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/n2wa4hje</a><br/>Synced 5 W&B file(s), 7954 media file(s), 45 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231006_174505-n2wa4hje/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1696616381628,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "MtQMTTn0oNWM"
   },
   "outputs": [],
   "source": [
    "# runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}