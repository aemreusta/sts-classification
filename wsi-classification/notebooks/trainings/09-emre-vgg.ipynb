{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 753,
     "status": "ok",
     "timestamp": 1696617902324,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "83c8Rn-n55mB",
    "outputId": "43df380b-d4d5-4e8e-826e-64e09db212dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Oct  6 18:45:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   32C    P0    45W / 400W |      0MiB / 40960MiB |      0%      Default |\n",
      "|                               |                      |             Disabled |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = \"\\n\".join(gpu_info)\n",
    "if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU\")\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696617902324,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "K2zAgcJF5_Sz",
    "outputId": "23fca70c-517a-4d25-dcca-1f9101e27994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your runtime has 89.6 gigabytes of available RAM\n",
      "\n",
      "You are using a high-RAM runtime!\n"
     ]
    }
   ],
   "source": [
    "from psutil import virtual_memory\n",
    "\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print(\"Your runtime has {:.1f} gigabytes of available RAM\\n\".format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"Not using a high-RAM runtime\")\n",
    "else:\n",
    "    print(\"You are using a high-RAM runtime!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13809,
     "status": "ok",
     "timestamp": 1696617916130,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "ciNEDCYc6HqG",
    "outputId": "40c8f38f-b272-45d1-a06c-04db8b91b0ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
      "Requirement already satisfied: ml-dtypes==0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.0)\n",
      "Requirement already satisfied: tensorboard<2.15,>=2.14 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: keras<2.15,>=2.14.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.14.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.4.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (0.7.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.15,>=2.14->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (5.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.15,>=2.14->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb -qU\n",
    "!pip install -U tensorflow\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3224,
     "status": "ok",
     "timestamp": 1696617919342,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "74AnNtVp6HnU",
    "outputId": "23f7435a-c8e7-4a38-a48c-01cdcb375da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "# Mount the Google Drive to access the files\n",
    "drive.mount(\"/content/gdrive/\")\n",
    "work_directory = \"/content/gdrive/MyDrive/wsi_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3859,
     "status": "ok",
     "timestamp": 1696617923195,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "AH3NpWmH6HlA",
    "outputId": "869837ca-ba54-4e9b-af3a-0974739a1bec"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Add the path to your project root directory\n",
    "if work_directory not in sys.path:\n",
    "    sys.path.append(work_directory)\n",
    "\n",
    "# my utility functions\n",
    "from utils.general import create_directory\n",
    "from utils.dataloader import select_case_data\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "import wandb\n",
    "\n",
    "# load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(work_directory, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1696617923196,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "7ctiuGum6Hi1",
    "outputId": "90e83b71-4e08-417d-c30c-3831534c5857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists: /content/gdrive/MyDrive/wsi_code/runs/40k/vgg19\n"
     ]
    }
   ],
   "source": [
    "# Define data directories\n",
    "DATASETS_PATH = os.path.join(work_directory, \"datasets\")\n",
    "PROCESSED_PATH = os.path.join(DATASETS_PATH, \"processed\")\n",
    "hdf5_file = os.path.join(PROCESSED_PATH, \"patchs_384_40k.hdf5\")\n",
    "run_dir = os.path.join(work_directory, \"runs\", \"40k\")\n",
    "\n",
    "# Create directories with datetime\n",
    "model_dir = os.path.join(run_dir, \"vgg19\")\n",
    "\n",
    "# Create the directories\n",
    "create_directory(model_dir)\n",
    "\n",
    "# Get the current datetime\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "log_path = os.path.join(model_dir, f\"{current_datetime}.log\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    filename=log_path,  # Specify the file name and path\n",
    "    filemode=\"w\",  # 'w' for write mode, use 'a' to append to an existing file\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 284966,
     "status": "ok",
     "timestamp": 1696618208158,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "tOjCnygJ6djf"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "logger.info(\"Loading and preprocessing data...\")\n",
    "validation_images, validation_labels, train_images, train_labels = select_case_data(\n",
    "    hdf5_file, selected_cases=[4]\n",
    ")\n",
    "\n",
    "# Define a normalization layer\n",
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = np.unique(train_labels).shape[\n",
    "    0\n",
    "]  # Replace with the actual number of classes\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "validation_labels = tf.keras.utils.to_categorical(validation_labels, num_classes)\n",
    "\n",
    "\n",
    "def preprocess_data(images, labels):\n",
    "    images = normalization_layer(images)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def create_and_preprocess_dataset(\n",
    "    images, labels, batch_size, augment=False, shuffle_buffer_size=1000\n",
    "):\n",
    "    # Create a dataset from the input images and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "    # Shuffle the dataset for randomness\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if augment:\n",
    "        # Apply data augmentation within the dataset pipeline\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_up_down(x), y))\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta=0.05), y)\n",
    "        )\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_contrast(x, lower=0.9, upper=1.1), y)\n",
    "        )\n",
    "\n",
    "    # Normalize the images\n",
    "    dataset = dataset.map(preprocess_data)\n",
    "\n",
    "    # Batch the dataset\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Prefetch for efficient loading during training\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Create TensorFlow datasets and apply normalization\n",
    "logger.info(\"Creating datasets and applying normalization...\")\n",
    "\n",
    "batch_size = 16  # You can adjust this based on your available memory\n",
    "num_parallel_calls = tf.data.AUTOTUNE\n",
    "\n",
    "normalized_validation_ds = create_and_preprocess_dataset(\n",
    "    validation_images, validation_labels, batch_size=batch_size\n",
    ")\n",
    "normalized_train_ds = create_and_preprocess_dataset(\n",
    "    train_images, train_labels, augment=False, batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Delete unused variables to free up memory\n",
    "del validation_images, validation_labels, train_images, train_labels\n",
    "\n",
    "logger.info(\"Data loading and preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 613,
     "status": "ok",
     "timestamp": 1696618208744,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "ZjTtOb_y6e7P"
   },
   "outputs": [],
   "source": [
    "vgg19 = tf.keras.applications.VGG19(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    classifier_activation=\"softmax\",\n",
    "    input_shape=(384, 384, 3),\n",
    ")\n",
    "\n",
    "vgg19.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(vgg19.output)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(vgg19.inputs, outputs, name=\"VGG19\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1696618208744,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "dcNaROSY6Hgo"
   },
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define ReduceLROnPlateau callback\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor=\"loss\", factor=0.5, patience=2, min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=model_dir,\n",
    "    histogram_freq=1,  # Enable histogram computation\n",
    "    write_graph=True,  # Write model graph to file\n",
    "    write_images=True,  # Write model weights to file\n",
    "    update_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 8675,
     "status": "ok",
     "timestamp": 1696618217416,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "6fttwfLU6HeW",
    "outputId": "b7e039c1-c533-4943-90d2-291bad983b28"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maemreusta\u001b[0m (\u001b[33mhacettepe-cerrahpasa-sts\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/content/wandb/run-20231006_185014-fyr1u7jb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/fyr1u7jb' target=\"_blank\">fancy-pond-45</a></strong> to <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/fyr1u7jb' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/fyr1u7jb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    }
   ],
   "source": [
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "else:\n",
    "    print(\"WANDB_API_KEY not found in the .env file.\")\n",
    "\n",
    "# Before wandb.init, call wandb.tensorboard.patch\n",
    "wandb.tensorboard.patch(\n",
    "    root_logdir=model_dir\n",
    ")  # Replace model_dir with your log directory\n",
    "wandb.init(\n",
    "    project=\"wsi-classification-40k\",\n",
    "    sync_tensorboard=True,\n",
    "    entity=\"hacettepe-cerrahpasa-sts\",\n",
    "    notes=\"vgg19_cross_4_final\",\n",
    "    tags=[\"vgg19\", \"cross_4\", \"final\"],\n",
    ")\n",
    "# Initialize wandb callback\n",
    "wandb_callback = wandb.keras.WandbCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3662067,
     "status": "ok",
     "timestamp": 1696621879472,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "1PAXEjpz6HcK",
    "outputId": "2042b207-502a-4e8c-b51d-15f8c00511a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1882 - categorical_accuracy: 0.9449 - precision: 0.9466 - recall: 0.9408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 96s 46ms/step - loss: 0.1881 - categorical_accuracy: 0.9449 - precision: 0.9466 - recall: 0.9409 - val_loss: 5.2818 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 2/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1942 - categorical_accuracy: 0.9521 - precision: 0.9542 - recall: 0.9501"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 90s 45ms/step - loss: 0.1941 - categorical_accuracy: 0.9521 - precision: 0.9542 - recall: 0.9502 - val_loss: 4.8759 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 3/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.1613 - categorical_accuracy: 0.9597 - precision: 0.9612 - recall: 0.9578 - val_loss: 5.0731 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 4/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.1409 - categorical_accuracy: 0.9642 - precision: 0.9658 - recall: 0.9627 - val_loss: 4.9170 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 5/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.1251 - categorical_accuracy: 0.9679 - precision: 0.9694 - recall: 0.9667 - val_loss: 5.0610 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 6/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1156 - categorical_accuracy: 0.9693 - precision: 0.9703 - recall: 0.9677"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 45ms/step - loss: 0.1155 - categorical_accuracy: 0.9693 - precision: 0.9703 - recall: 0.9677 - val_loss: 4.8344 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 7/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.1075 - categorical_accuracy: 0.9710 - precision: 0.9721 - recall: 0.9696 - val_loss: 4.9538 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 8/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0980 - categorical_accuracy: 0.9725 - precision: 0.9738 - recall: 0.9715"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 90s 45ms/step - loss: 0.0980 - categorical_accuracy: 0.9725 - precision: 0.9738 - recall: 0.9716 - val_loss: 4.8331 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 9/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0941 - categorical_accuracy: 0.9744 - precision: 0.9753 - recall: 0.9734 - val_loss: 4.8840 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 10/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0882 - categorical_accuracy: 0.9752 - precision: 0.9766 - recall: 0.9739 - val_loss: 4.9331 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 11/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0819 - categorical_accuracy: 0.9765 - precision: 0.9782 - recall: 0.9753 - val_loss: 4.9046 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 12/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0801 - categorical_accuracy: 0.9778 - precision: 0.9788 - recall: 0.9768 - val_loss: 4.8770 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 13/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0760 - categorical_accuracy: 0.9791 - precision: 0.9799 - recall: 0.9780 - val_loss: 4.9069 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 14/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0722 - categorical_accuracy: 0.9793 - precision: 0.9801 - recall: 0.9782 - val_loss: 4.9184 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 15/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0711 - categorical_accuracy: 0.9794 - precision: 0.9805 - recall: 0.9783 - val_loss: 4.9335 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 16/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0680 - categorical_accuracy: 0.9799 - precision: 0.9811 - recall: 0.9786 - val_loss: 4.8980 - val_categorical_accuracy: 0.2499 - val_precision: 0.2498 - val_recall: 0.2498 - lr: 5.0000e-05\n",
      "Epoch 17/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0673 - categorical_accuracy: 0.9806 - precision: 0.9817 - recall: 0.9800 - val_loss: 5.0094 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 18/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0649 - categorical_accuracy: 0.9812 - precision: 0.9821 - recall: 0.9800 - val_loss: 4.8784 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 19/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0625 - categorical_accuracy: 0.9824 - precision: 0.9839 - recall: 0.9817 - val_loss: 5.0320 - val_categorical_accuracy: 0.2498 - val_precision: 0.2498 - val_recall: 0.2498 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0600 - categorical_accuracy: 0.9824 - precision: 0.9837 - recall: 0.9816 - val_loss: 4.9883 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0592 - categorical_accuracy: 0.9831 - precision: 0.9840 - recall: 0.9821 - val_loss: 4.9977 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0582 - categorical_accuracy: 0.9834 - precision: 0.9841 - recall: 0.9825 - val_loss: 5.0499 - val_categorical_accuracy: 0.2499 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0565 - categorical_accuracy: 0.9832 - precision: 0.9841 - recall: 0.9823 - val_loss: 4.9948 - val_categorical_accuracy: 0.2500 - val_precision: 0.2501 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0540 - categorical_accuracy: 0.9837 - precision: 0.9848 - recall: 0.9827 - val_loss: 5.0452 - val_categorical_accuracy: 0.2499 - val_precision: 0.2500 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0548 - categorical_accuracy: 0.9843 - precision: 0.9852 - recall: 0.9835 - val_loss: 5.1768 - val_categorical_accuracy: 0.2500 - val_precision: 0.2500 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0537 - categorical_accuracy: 0.9840 - precision: 0.9851 - recall: 0.9830 - val_loss: 5.1657 - val_categorical_accuracy: 0.2500 - val_precision: 0.2501 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0501 - categorical_accuracy: 0.9850 - precision: 0.9858 - recall: 0.9840 - val_loss: 5.2624 - val_categorical_accuracy: 0.2500 - val_precision: 0.2499 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0515 - categorical_accuracy: 0.9854 - precision: 0.9865 - recall: 0.9846 - val_loss: 5.1209 - val_categorical_accuracy: 0.2498 - val_precision: 0.2499 - val_recall: 0.2498 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0493 - categorical_accuracy: 0.9848 - precision: 0.9860 - recall: 0.9840 - val_loss: 5.2311 - val_categorical_accuracy: 0.2501 - val_precision: 0.2500 - val_recall: 0.2499 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0470 - categorical_accuracy: 0.9865 - precision: 0.9873 - recall: 0.9859 - val_loss: 5.2255 - val_categorical_accuracy: 0.2501 - val_precision: 0.2503 - val_recall: 0.2501 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "2000/2000 [==============================] - 88s 44ms/step - loss: 0.0497 - categorical_accuracy: 0.9850 - precision: 0.9859 - recall: 0.9842 - val_loss: 5.2596 - val_categorical_accuracy: 0.2500 - val_precision: 0.2502 - val_recall: 0.2500 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "2000/2000 [==============================] - 87s 44ms/step - loss: 0.0492 - categorical_accuracy: 0.9855 - precision: 0.9864 - recall: 0.9844 - val_loss: 5.0733 - val_categorical_accuracy: 0.2503 - val_precision: 0.2505 - val_recall: 0.2503 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0648 - categorical_accuracy: 0.9819 - precision: 0.9838 - recall: 0.9804"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 45ms/step - loss: 0.0647 - categorical_accuracy: 0.9819 - precision: 0.9838 - recall: 0.9804 - val_loss: 4.2584 - val_categorical_accuracy: 0.2517 - val_precision: 0.2522 - val_recall: 0.2510 - lr: 2.5000e-05\n",
      "Epoch 34/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.0637 - categorical_accuracy: 0.9819 - precision: 0.9838 - recall: 0.9803"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 45ms/step - loss: 0.0636 - categorical_accuracy: 0.9819 - precision: 0.9838 - recall: 0.9803 - val_loss: 4.1825 - val_categorical_accuracy: 0.2519 - val_precision: 0.2528 - val_recall: 0.2511 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1066 - categorical_accuracy: 0.9681 - precision: 0.9723 - recall: 0.9651"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 46ms/step - loss: 0.1065 - categorical_accuracy: 0.9681 - precision: 0.9723 - recall: 0.9651 - val_loss: 3.1486 - val_categorical_accuracy: 0.2682 - val_precision: 0.2730 - val_recall: 0.2657 - lr: 1.2500e-05\n",
      "Epoch 36/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.1036 - categorical_accuracy: 0.9701 - precision: 0.9741 - recall: 0.9666"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 45ms/step - loss: 0.1035 - categorical_accuracy: 0.9702 - precision: 0.9741 - recall: 0.9667 - val_loss: 3.0983 - val_categorical_accuracy: 0.2697 - val_precision: 0.2740 - val_recall: 0.2665 - lr: 1.2500e-05\n",
      "Epoch 37/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.2191 - categorical_accuracy: 0.9306 - precision: 0.9416 - recall: 0.9198"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 45ms/step - loss: 0.2190 - categorical_accuracy: 0.9307 - precision: 0.9416 - recall: 0.9198 - val_loss: 2.1167 - val_categorical_accuracy: 0.3460 - val_precision: 0.3570 - val_recall: 0.3305 - lr: 6.2500e-06\n",
      "Epoch 38/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.2346 - categorical_accuracy: 0.9267 - precision: 0.9383 - recall: 0.9141"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 46ms/step - loss: 0.2345 - categorical_accuracy: 0.9267 - precision: 0.9383 - recall: 0.9142 - val_loss: 2.0311 - val_categorical_accuracy: 0.3594 - val_precision: 0.3697 - val_recall: 0.3409 - lr: 6.2500e-06\n",
      "Epoch 39/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.4847 - categorical_accuracy: 0.8198 - precision: 0.8508 - recall: 0.7801"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 45ms/step - loss: 0.4846 - categorical_accuracy: 0.8199 - precision: 0.8509 - recall: 0.7802 - val_loss: 1.3319 - val_categorical_accuracy: 0.5009 - val_precision: 0.5289 - val_recall: 0.4708 - lr: 3.1250e-06\n",
      "Epoch 40/100\n",
      "1999/2000 [============================>.] - ETA: 0s - loss: 0.4663 - categorical_accuracy: 0.8264 - precision: 0.8581 - recall: 0.7867"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/content/wandb/run-20231006_185014-fyr1u7jb/files/model-best)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r2000/2000 [==============================] - 91s 45ms/step - loss: 0.4663 - categorical_accuracy: 0.8265 - precision: 0.8581 - recall: 0.7867 - val_loss: 1.2934 - val_categorical_accuracy: 0.5106 - val_precision: 0.5431 - val_recall: 0.4837 - lr: 3.1250e-06\n"
     ]
    }
   ],
   "source": [
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data=normalized_validation_ds,\n",
    "    epochs=100,\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        wandb_callback,\n",
    "        early_stopping,\n",
    "        reduce_lr_on_plateau,\n",
    "        tensorboard_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 761
    },
    "executionInfo": {
     "elapsed": 23597,
     "status": "ok",
     "timestamp": 1696621903039,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "WgCNmq5aCYlE",
    "outputId": "3cbe6347-5091-4e05-bad8-0c032050d2ec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>categorical_accuracy</td><td>▆▇▇▇▇▇▇▇▇█████████████████████████▇▇▆▅▁▁</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>global_step</td><td>▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▄██</td></tr><tr><td>precision</td><td>▆▆▇▇▇▇▇▇▇▇████████████████████████▇▇▆▅▁▁</td></tr><tr><td>recall</td><td>▆▇▇▇▇▇▇███████████████████████████▇▇▆▆▁▁</td></tr><tr><td>train/epoch_categorical_accuracy</td><td>▆▇▇▇▇▇▇▇▇█████████████████████████▇▇▆▅▁▁</td></tr><tr><td>train/epoch_loss</td><td>▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▄██</td></tr><tr><td>train/epoch_lr</td><td>████████████████████████████████▄▄▂▂▁▁▁▁</td></tr><tr><td>train/epoch_precision</td><td>▆▆▇▇▇▇▇▇▇▇████████████████████████▇▇▆▅▁▁</td></tr><tr><td>train/epoch_recall</td><td>▆▇▇▇▇▇▇███████████████████████████▇▇▆▆▁▁</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>val_categorical_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▄██</td></tr><tr><td>val_loss</td><td>█▇█▇█▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█████████▆▆▄▄▂▂▁▁</td></tr><tr><td>val_precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▄██</td></tr><tr><td>val_recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄██</td></tr><tr><td>validation/epoch_categorical_accuracy</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▄██</td></tr><tr><td>validation/epoch_loss</td><td>█▇█▇█▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█████████▆▆▄▄▂▂▁▁</td></tr><tr><td>validation/epoch_precision</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▄██</td></tr><tr><td>validation/epoch_recall</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄██</td></tr><tr><td>validation/evaluation_categorical_accuracy_vs_iterations</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▄▄██</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>█▇█▇█▇▇▇▇▇▇▇▇▇▇▇█▇█▇██▇█████████▆▆▄▄▂▂▁▁</td></tr><tr><td>validation/evaluation_precision_vs_iterations</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▄▄██</td></tr><tr><td>validation/evaluation_recall_vs_iterations</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▃▄██</td></tr><tr><td>validation/global_step</td><td>▁▁▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>best_epoch</td><td>39</td></tr><tr><td>best_val_loss</td><td>1.29337</td></tr><tr><td>categorical_accuracy</td><td>0.82647</td></tr><tr><td>epoch</td><td>39</td></tr><tr><td>global_step</td><td>80000</td></tr><tr><td>loss</td><td>0.46627</td></tr><tr><td>precision</td><td>0.8581</td></tr><tr><td>recall</td><td>0.78672</td></tr><tr><td>train/epoch_categorical_accuracy</td><td>0.82647</td></tr><tr><td>train/epoch_loss</td><td>0.46627</td></tr><tr><td>train/epoch_lr</td><td>0.0</td></tr><tr><td>train/epoch_precision</td><td>0.8581</td></tr><tr><td>train/epoch_recall</td><td>0.78672</td></tr><tr><td>train/global_step</td><td>39</td></tr><tr><td>val_categorical_accuracy</td><td>0.51063</td></tr><tr><td>val_loss</td><td>1.29337</td></tr><tr><td>val_precision</td><td>0.54308</td></tr><tr><td>val_recall</td><td>0.48375</td></tr><tr><td>validation/epoch_categorical_accuracy</td><td>0.51063</td></tr><tr><td>validation/epoch_loss</td><td>1.29337</td></tr><tr><td>validation/epoch_precision</td><td>0.54308</td></tr><tr><td>validation/epoch_recall</td><td>0.48375</td></tr><tr><td>validation/evaluation_categorical_accuracy_vs_iterations</td><td>0.51063</td></tr><tr><td>validation/evaluation_loss_vs_iterations</td><td>1.29337</td></tr><tr><td>validation/evaluation_precision_vs_iterations</td><td>0.54308</td></tr><tr><td>validation/evaluation_recall_vs_iterations</td><td>0.48375</td></tr><tr><td>validation/global_step</td><td>39</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fancy-pond-45</strong> at: <a href='https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/fyr1u7jb' target=\"_blank\">https://wandb.ai/hacettepe-cerrahpasa-sts/wsi-classification-40k/runs/fyr1u7jb</a><br/>Synced 5 W&B file(s), 801 media file(s), 60 artifact file(s) and 3 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231006_185014-fyr1u7jb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1696621903039,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "EP06dEcO6HXu"
   },
   "outputs": [],
   "source": [
    "# runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}