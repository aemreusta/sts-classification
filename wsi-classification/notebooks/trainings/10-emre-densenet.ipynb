{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1695048934971,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "T-xv02iw7Zjd",
    "outputId": "7f762bf1-d03d-416a-9b5b-fd2b5aa0761b"
   },
   "outputs": [],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = \"\\n\".join(gpu_info)\n",
    "if gpu_info.find(\"failed\") >= 0:\n",
    "    print(\"Not connected to a GPU\")\n",
    "else:\n",
    "    print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1695048934971,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "3Zwtzaxq7zQj",
    "outputId": "2be682e4-9795-4d32-902d-ff3d22186e79"
   },
   "outputs": [],
   "source": [
    "from psutil import virtual_memory\n",
    "\n",
    "ram_gb = virtual_memory().total / 1e9\n",
    "print(\"Your runtime has {:.1f} gigabytes of available RAM\\n\".format(ram_gb))\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"Not using a high-RAM runtime\")\n",
    "else:\n",
    "    print(\"You are using a high-RAM runtime!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17356,
     "status": "ok",
     "timestamp": 1695048952321,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "RvWOKuol7zOC",
    "outputId": "6e497b36-eaf3-47a8-e772-4423d5485c55"
   },
   "outputs": [],
   "source": [
    "!pip install wandb -qU\n",
    "!pip install -U tensorflow\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25744,
     "status": "ok",
     "timestamp": 1695048978058,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "D7VlYNog7zLf",
    "outputId": "0ce57050-ed09-4998-eca1-d1e59e65fd8d"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive, runtime\n",
    "\n",
    "# Mount the Google Drive to access the files\n",
    "drive.mount(\"/content/gdrive/\")\n",
    "work_directory = \"/content/gdrive/MyDrive/wsi_code\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8462,
     "status": "ok",
     "timestamp": 1695048986504,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "HSBUPld17zJS",
    "outputId": "e03d83ce-a601-439c-dcbd-7abad42376c7"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import logging\n",
    "\n",
    "# Add the path to your project root directory\n",
    "if work_directory not in sys.path:\n",
    "    sys.path.append(work_directory)\n",
    "\n",
    "# my utility functions\n",
    "from utils.general import create_directory\n",
    "from utils.dataloader import select_case_data\n",
    "\n",
    "# TensorFlow and Keras imports\n",
    "import tensorflow as tf\n",
    "from keras.layers import (\n",
    "    Dense,\n",
    "    GlobalAveragePooling2D,\n",
    ")\n",
    "\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    TensorBoard,\n",
    ")\n",
    "import wandb\n",
    "\n",
    "# load env variables\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(work_directory, \".env\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1695048986505,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "mcwRUyhd7zHJ",
    "outputId": "f3d599b5-70b0-416d-8bcb-311f39896ef7"
   },
   "outputs": [],
   "source": [
    "# Define data directories\n",
    "DATASETS_PATH = os.path.join(work_directory, \"datasets\")\n",
    "PROCESSED_PATH = os.path.join(DATASETS_PATH, \"processed\")\n",
    "hdf5_file = os.path.join(PROCESSED_PATH, \"patchs_384_40k.hdf5\")\n",
    "run_dir = os.path.join(work_directory, \"runs\", \"40k\")\n",
    "\n",
    "# Create directories with datetime\n",
    "model_dir = os.path.join(run_dir, \"densenet\")\n",
    "\n",
    "# Create the directories\n",
    "create_directory(model_dir)\n",
    "\n",
    "# Get the current datetime\n",
    "current_datetime = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "log_path = os.path.join(model_dir, f\"{current_datetime}.log\")\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    filename=log_path,  # Specify the file name and path\n",
    "    filemode=\"w\",  # 'w' for write mode, use 'a' to append to an existing file\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 337113,
     "status": "ok",
     "timestamp": 1695049325929,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "FfnhqB-F7zFE"
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "logger.info(\"Loading and preprocessing data...\")\n",
    "validation_images, validation_labels, train_images, train_labels = select_case_data(\n",
    "    hdf5_file, selected_cases=[0]\n",
    ")\n",
    "\n",
    "# Define a normalization layer\n",
    "normalization_layer = tf.keras.layers.Rescaling(1.0 / 255)\n",
    "\n",
    "# One-hot encode the labels\n",
    "num_classes = np.unique(train_labels).shape[\n",
    "    0\n",
    "]  # Replace with the actual number of classes\n",
    "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
    "validation_labels = tf.keras.utils.to_categorical(validation_labels, num_classes)\n",
    "\n",
    "\n",
    "def preprocess_data(images, labels):\n",
    "    images = normalization_layer(images)\n",
    "    return images, labels\n",
    "\n",
    "\n",
    "def create_and_preprocess_dataset(\n",
    "    images, labels, batch_size, augment=False, shuffle_buffer_size=1000\n",
    "):\n",
    "    # Create a dataset from the input images and labels\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "    # Shuffle the dataset for randomness\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "\n",
    "    if augment:\n",
    "        # Apply data augmentation within the dataset pipeline\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_left_right(x), y))\n",
    "        dataset = dataset.map(lambda x, y: (tf.image.random_flip_up_down(x), y))\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_brightness(x, max_delta=0.05), y)\n",
    "        )\n",
    "        dataset = dataset.map(\n",
    "            lambda x, y: (tf.image.random_contrast(x, lower=0.9, upper=1.1), y)\n",
    "        )\n",
    "\n",
    "    # Normalize the images\n",
    "    dataset = dataset.map(preprocess_data)\n",
    "\n",
    "    # Batch the dataset\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    # Prefetch for efficient loading during training\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# Create TensorFlow datasets and apply normalization\n",
    "logger.info(\"Creating datasets and applying normalization...\")\n",
    "\n",
    "batch_size = 16  # You can adjust this based on your available memory\n",
    "num_parallel_calls = tf.data.AUTOTUNE\n",
    "\n",
    "normalized_validation_ds = create_and_preprocess_dataset(\n",
    "    validation_images, validation_labels, batch_size=batch_size\n",
    ")\n",
    "normalized_train_ds = create_and_preprocess_dataset(\n",
    "    train_images, train_labels, augment=False, batch_size=batch_size\n",
    ")\n",
    "\n",
    "# Delete unused variables to free up memory\n",
    "del validation_images, validation_labels, train_images, train_labels\n",
    "\n",
    "logger.info(\"Data loading and preprocessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5952,
     "status": "ok",
     "timestamp": 1695049331877,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "of7jUmZF76-Z",
    "outputId": "55fda952-b5e6-44b6-f429-be45d54ada34"
   },
   "outputs": [],
   "source": [
    "densenet = tf.keras.applications.DenseNet201(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    classifier_activation=\"softmax\",\n",
    "    input_shape=(384, 384, 3),\n",
    ")\n",
    "\n",
    "densenet.trainable = False\n",
    "\n",
    "x = GlobalAveragePooling2D()(densenet.output)\n",
    "x = Dense(256, activation=\"relu\")(x)\n",
    "outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "model = tf.keras.Model(densenet.inputs, outputs, name=\"DenseNet201\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.CategoricalAccuracy(),\n",
    "        tf.keras.metrics.Precision(),\n",
    "        tf.keras.metrics.Recall(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1695049331877,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "VqgHItBV3f4X"
   },
   "outputs": [],
   "source": [
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Define ReduceLROnPlateau callback\n",
    "reduce_lr_on_plateau = ReduceLROnPlateau(\n",
    "    monitor=\"loss\", factor=0.5, patience=2, min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Define TensorBoard callback\n",
    "tensorboard_callback = TensorBoard(\n",
    "    log_dir=model_dir,\n",
    "    histogram_freq=1,  # Enable histogram computation\n",
    "    write_graph=True,  # Write model graph to file\n",
    "    write_images=True,  # Write model weights to file\n",
    "    update_freq=\"epoch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6878,
     "status": "ok",
     "timestamp": 1695049338751,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "U1qxdbac7zC_",
    "outputId": "655aca07-ef31-4fec-eea4-b0a57c4ed888"
   },
   "outputs": [],
   "source": [
    "wandb_api_key = os.getenv(\"WANDB_API_KEY\")\n",
    "\n",
    "if wandb_api_key:\n",
    "    wandb.login(key=wandb_api_key)\n",
    "else:\n",
    "    print(\"WANDB_API_KEY not found in the .env file.\")\n",
    "\n",
    "# Before wandb.init, call wandb.tensorboard.patch\n",
    "wandb.tensorboard.patch(\n",
    "    root_logdir=model_dir\n",
    ")  # Replace model_dir with your log directory\n",
    "wandb.init(\n",
    "    project=\"wsi-classification-40k\",\n",
    "    sync_tensorboard=True,\n",
    "    entity=\"hacettepe-cerrahpasa-sts\",\n",
    "    notes=\"densenet_cross_0_final\",\n",
    "    tags=[\"densenet\", \"201\", \"cross_0\", \"final\"],\n",
    ")\n",
    "# Initialize wandb callback\n",
    "wandb_callback = wandb.keras.WandbCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1085904,
     "status": "ok",
     "timestamp": 1695050424650,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "zvd2TXL97y-k",
    "outputId": "6a889fce-0f16-4bcc-95cb-415238161575"
   },
   "outputs": [],
   "source": [
    "# Train the model with callbacks\n",
    "history = model.fit(\n",
    "    normalized_train_ds,\n",
    "    validation_data=normalized_validation_ds,\n",
    "    epochs=100,\n",
    "    workers=-1,\n",
    "    use_multiprocessing=True,\n",
    "    callbacks=[\n",
    "        wandb_callback,\n",
    "        early_stopping,\n",
    "        reduce_lr_on_plateau,\n",
    "        tensorboard_callback,\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54063,
     "status": "ok",
     "timestamp": 1695050478450,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "LI5lbw9EiHyW",
    "outputId": "32d18efd-ed0b-4b1a-9b31-38fe76e9fe46"
   },
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 781,
     "status": "ok",
     "timestamp": 1695050479223,
     "user": {
      "displayName": "Ahmet Emre Usta",
      "userId": "15508369964865834704"
     },
     "user_tz": -180
    },
    "id": "yTwpAuUg8LLZ"
   },
   "outputs": [],
   "source": [
    "runtime.unassign()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
